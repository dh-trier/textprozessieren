{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "117330e9",
   "metadata": {},
   "source": [
    "# Pandas 2: Einlesen und Filtern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed3fd6d",
   "metadata": {},
   "source": [
    "## Einleitung\n",
    "\n",
    "Häufig haben wir es in den Digital Humanities mit Daten in einem tabellarischen Format, bspw. in Form einer CSV-Datei, zu tun. Oft sind das Metadaten oder auch Ergebnisse von Berechnungen. \n",
    "\n",
    "Solche Tabellen lassen sich in Python sehr gut mit pandas als DataFrame öffnen, analysieren und visualisieren. Das probieren wir hier im Sinne einer vertiefenden Einführung in DataFrames mit einem realen Beispieldatensatz vom 'Index of DH Conferences' aus. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329be7d0",
   "metadata": {},
   "source": [
    "## Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95b3caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3770f2",
   "metadata": {},
   "source": [
    "## Eine CSV-Datei einlesen\n",
    "\n",
    "- Öffnen der Datei mit `with open`\n",
    "- Einlesen als DataFrame mit `read_csv` (Parameter: `sep` für Separator und `index_col` für die Spalte, die als Index verwendet werden soll)\n",
    "- Weitere Infos zu den Parametern: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52baf797",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = join(\"..\", \"..\", \"datasets\", \"tabular\", \"idhc_conferences.csv\")\n",
    "\n",
    "def read_csvfile(csvfile): \n",
    "    with open(csvfile, \"r\", encoding=\"utf8\") as infile: \n",
    "        data = pd.read_csv(infile, sep=\",\", index_col=0)\n",
    "    #print(data.head())\n",
    "    return data\n",
    "\n",
    "data = read_csvfile(csvfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c58f3b",
   "metadata": {},
   "source": [
    "## DataFrame aus Listen erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb3306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Jahr    Stadt\n",
      "DHd2015  2015     Graz\n",
      "DHd2016  2016  Leipzig\n",
      "DHd2017  2017     Bern\n",
      "{'DHd2015': (2015, 'Graz'), 'DHd2016': (2016, 'Leipzig'), 'DHd2017': (2017, 'Bern')}\n",
      "         Jahr    Stadt\n",
      "DHd2015  2015     Graz\n",
      "DHd2016  2016  Leipzig\n",
      "DHd2017  2017     Bern\n"
     ]
    }
   ],
   "source": [
    "conferences = [\"DHd2015\", \"DHd2016\", \"DHd2017\"]\n",
    "headers = [\"Jahr\", \"Stadt\"]\n",
    "jahre = [2015, 2016, 2017]\n",
    "staedte = [\"Graz\", \"Leipzig\", \"Bern\"]\n",
    "\n",
    "# DataFrame aus Listen\n",
    "confdata = list(zip(jahre,staedte))\n",
    "confdf = pd.DataFrame(confdata, index=conferences, columns=headers)\n",
    "print(confdf)\n",
    "\n",
    "# DataFrame aus Dict\n",
    "confdata1 = list(zip(jahre, staedte))\n",
    "confdata = dict(zip(conferences, confdata1))\n",
    "print(confdata)\n",
    "confdf = pd.DataFrame.from_dict(confdata, orient=\"index\", columns=headers)\n",
    "print(confdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92d542",
   "metadata": {},
   "source": [
    "## Einen Eindruck von Umfang und Inhalt bekommen\n",
    "\n",
    "- Größe der Tabelle mit `.shape`\n",
    "- Liste der Spaltentitel mit `.columns`\n",
    "- Index mit `.index`\n",
    "- Anfang der Tabelle mit `.head()`\n",
    "- Datentypen der Spalten mit `.dtypes`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52672f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (499, 11)\n",
      "columns ['year', 'short_title', 'url', 'start_date', 'end_date', 'city', 'country', 'entry_status', 'program_available', 'abstracts_available', 'label']\n",
      "index [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51]\n"
     ]
    }
   ],
   "source": [
    "print(\"shape\", data.shape)\n",
    "print(\"columns\", list(data.columns))\n",
    "print(\"index\", list(data.index[0:50]))\n",
    "#print(data.head())\n",
    "#print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f168e2",
   "metadata": {},
   "source": [
    "## Teile der Tabelle auswählen\n",
    "\n",
    "- Slicing nach Index-Positionen mit `iloc`\n",
    "- Slicing mit Labels mit `loc`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04dee8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(4, 2)\n",
      "    start_date    end_date\n",
      "id                        \n",
      "1   2000-07-21  2000-07-25\n",
      "2   2001-07-13  2001-07-16\n",
      "3   2002-07-23  2002-07-28\n",
      "4   2003-05-29  2003-06-02\n"
     ]
    }
   ],
   "source": [
    "def select_from_data(data): \n",
    "    # mit iloc\n",
    "    selected = data.iloc[0:3,0:3] # [Zeilen,Spalten]\n",
    "    selected = data.iloc[15:20,5:8] \n",
    "    selected = data.iloc[100:105,:] \n",
    "    selected = data.iloc[:,3:5] \n",
    "    selected = data.loc[:,\"city\"]\n",
    "    selected = data.loc[112, \"city\"] # Index=int!\n",
    "    selected = data.loc[[48,112], \"city\"] # Liste!\n",
    "    selected = data.loc[[1,2,3,4], [\"start_date\", \"end_date\"]] # Liste!\n",
    "    return selected\n",
    "\n",
    "selected = select_from_data(data)\n",
    "print(type(selected))\n",
    "print(selected.shape)\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00913ab9",
   "metadata": {},
   "source": [
    "## Die Tabelle nach bestimmten Kriterien filtern\n",
    "\n",
    "- Bestimmte Zeilen oder Spalten löschen mit `.drop()`\n",
    "- Zeilen löschen, wenn eine Zelle einen bestimmten Wert hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07fcbfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 11)\n",
      "[2015, 2020, 2006]\n"
     ]
    }
   ],
   "source": [
    "# Zeilen, die in der Spalte \"city\" den Wert \"London\" haben\n",
    "filtered = data[data[\"city\"] == \"London\"]\n",
    "\n",
    "# Zwei Kriterien: Stadt (string) und Jahr (int)\n",
    "filtered = data[(data[\"city\"] == \"Berlin\") & (data[\"year\"] >= 1995)]\n",
    "\n",
    "print(filtered.shape) # Zeilen,Spalten\n",
    "print(list(filtered.loc[:,\"year\"])) # Welche Jahre, als Liste\n",
    "#print(filtered.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301508c0",
   "metadata": {},
   "source": [
    "## Berechnungen auf der Tabelle ausführen\n",
    "\n",
    "Dafür ist es oft nützlich, numpy zu verwenden. \n",
    "\n",
    "- Mittelwert, Median, Standardabweichung einer Zeile oder Spalte berechnen\n",
    "- Andere Berechnung auf der Grundlage von zwei Zellen pro Zeile\n",
    "- Ergebnis als neue Spalte zum DataFrame hinzufügen\n",
    "- Hier am Beispiel der Konferenzdaten, daher siehe auch: https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b60b0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "2021     5\n",
      "2020    18\n",
      "2019    38\n",
      "2018    38\n",
      "2017    32\n",
      "2016    31\n",
      "2015    27\n",
      "2014    26\n",
      "2013    18\n",
      "2012    17\n",
      "2011    14\n",
      "2010    11\n",
      "2009    12\n",
      "2008    12\n",
      "2007    10\n",
      "2006    10\n",
      "2005     9\n",
      "2004    10\n",
      "2003     9\n",
      "2002    10\n",
      "2001     9\n",
      "2000     8\n",
      "1999     6\n",
      "1998     7\n",
      "1997     7\n",
      "1996     4\n",
      "1995     5\n",
      "1994     7\n",
      "1993     4\n",
      "1992     4\n",
      "1991     6\n",
      "1990     7\n",
      "1989     4\n",
      "1988     6\n",
      "1987     6\n",
      "1986     3\n",
      "1985     3\n",
      "1984     1\n",
      "1983     3\n",
      "1982     1\n",
      "1981     3\n",
      "1980     3\n",
      "1979     3\n",
      "1978     2\n",
      "1977     2\n",
      "1976     1\n",
      "1975     2\n",
      "1974     2\n",
      "1973     1\n",
      "1972     1\n",
      "1970     3\n",
      "1969     4\n",
      "1968     1\n",
      "1967     2\n",
      "1966     2\n",
      "1965     5\n",
      "1964     3\n",
      "1960     1\n",
      "Name: year, dtype: int64\n",
      "id\n",
      "1     4 days\n",
      "2     3 days\n",
      "3     5 days\n",
      "4     4 days\n",
      "5     5 days\n",
      "       ...  \n",
      "504   3 days\n",
      "505   3 days\n",
      "506   2 days\n",
      "507   3 days\n",
      "508   3 days\n",
      "Length: 499, dtype: timedelta64[ns]\n",
      "[-6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 369.0, 1096.0, nan, -7.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 63.0, 1098.0, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, nan, nan, 2.0, 2.0, 2.0, 3.0, 4.0, 5.0, nan, -2920.0, -59.0, -28.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 5.0, 21.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 366.0]\n",
      "    start_date    end_date  duration\n",
      "id                                  \n",
      "1   2000-07-21  2000-07-25       4.0\n",
      "2   2001-07-13  2001-07-16       3.0\n",
      "3   2002-07-23  2002-07-28       5.0\n",
      "4   2003-05-29  2003-06-02       4.0\n",
      "5   2004-06-11  2004-06-16       5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Median / Mittelwert der Konferenzjahre\n",
    "result = np.median(data.loc[:,\"year\"])\n",
    "result = np.mean(data.loc[:,\"year\"])\n",
    "#print(result)\n",
    "\n",
    "# Wie viele Konferenzen gab es denn pro Jahr? Mit Sortierung\n",
    "yearcounts = data[\"year\"].value_counts()\n",
    "print(type(yearcounts))\n",
    "yearcounts.sort_values(inplace=True, ascending=False)\n",
    "yearcounts.sort_index(inplace=True, ascending=False)\n",
    "print(yearcounts)\n",
    "\n",
    "# Mittlere Dauer der Konferenzen in Tagen\n",
    "filtered = data.loc[:,[\"start_date\", \"end_date\"]]\n",
    "filtered.dropna(inplace=True) # Unvollständige Einträge löschen\n",
    "#print(filtered.head())\n",
    "duration = pd.to_datetime(data[\"end_date\"], errors=\"ignore\") - pd.to_datetime(data[\"start_date\"], errors=\"ignore\")\n",
    "print(duration)\n",
    "print(sorted(list(duration.dt.days)))\n",
    "\n",
    "# Dauer in Tagen der Tabelle hinzufügen\n",
    "filtered[\"duration\"] = duration.dt.days\n",
    "print(filtered.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71673964",
   "metadata": {},
   "source": [
    "## Einen DataFrame abspeichern\n",
    "\n",
    "Den eben erstellen Dataframe mit den Konferenzdauern wollen wir jetzt abspeichern. \n",
    "\n",
    "- eine neue Datei anlegen mit `with open()`\n",
    "- Einen DataFrame als CSV herauschreiben mit `.to_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a5f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(filtered): \n",
    "    with open(\"meinetabelle.csv\", \"w\", encoding=\"utf8\") as outfile: \n",
    "        filtered.to_csv(outfile, sep=\";\")\n",
    "\n",
    "save_dataframe(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297f41a",
   "metadata": {},
   "source": [
    "## Weitere Themen\n",
    "\n",
    "- Berechnungen ausführen\n",
    "- Informationen aus einem DataFrame visualisieren (direkt in pandas mit `.plot()` oder beispielsweise mit der Library seaborn). \n",
    "- Einen DataFrame nach einem bestimmten Kriterium in mehrere Teile aufteilen mit `.groupby`. \n",
    "- Mehrere DataFrames miteinander verbinden mit `merge`, `concat` und/oder `join`. \n",
    "- Einen DataFrame aus mehreren Listen (mit `dict(zip[])`), aus einem Dictionary (mit `from_dict`) oder aus mehreren `Series` erstellen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85ad12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6649cb8e",
   "metadata": {},
   "source": [
    "# Creating Semantic Word Clusters from Word2Vec Model \n",
    "\n",
    "\n",
    "Script for loading an existing word2vec model and performing a word-level\n",
    "clustering using the BIRCH clustering algorithm. Results in multiple list\n",
    "of words that are semantically related. \n",
    "\n",
    "Output: A TSV file with cluster number, cluster size and words in each cluster. \n",
    "\n",
    "The sample models used here are available from Zenodo: \n",
    "- French Novel: https://doi.org/10.5281/zenodo.6004717\n",
    "- French Wikipedia: https://doi.org/10.5281/zenodo.162792 (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93435630",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3fbfdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import pandas as pd \n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.cluster import Birch\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21021b8",
   "metadata": {},
   "source": [
    "## Files and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddba9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfolder = join(\"..\", \"..\", \"..\", \"..\", \"..\", \"..\", \"Dropbox\", \"06-Analysen\", \"2017\", \"w2v\", \"models\")\n",
    "modelfiles = {\"roman20-small\" : join(modelfolder, \"roman20_mdt=skgr-opt=negsam-itr=10-dim=200-win=6-min=200.gensim\"),\n",
    "              \"roman20-medium\": join(modelfolder, \"roman20_mdt=skgr-opt=negsam-itr=10-dim=300-win=6-min=100.gensim\"),\n",
    "              \"romans20-large\" : join(modelfolder, \"roman20_mdt=skgr-opt=negsam-itr=10-dim=300-win=6-min=50.gensim\"),\n",
    "              \"frwiki17-medium\": join(modelfolder, \"frwiki17_mdt=skgr-opt=negsam-itr=20-dim=200-win=8-min=200.gensim\")}\n",
    "\n",
    "modelname = \"frwiki17-medium\"\n",
    "num_clusters = 600\n",
    "resultsfile = \"wordclusters_\" + modelname + \"-model_\" + str(num_clusters) + \"-clusters.tsv\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c50a8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cf52a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(modelfile): \n",
    "    \"\"\" Loads an existing word2vec model in Keyed vector format. \"\"\"\n",
    "    model = gensim.models.Word2Vec.load(modelfile)\n",
    "    vocab = model.wv.index_to_key\n",
    "    return model, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebe4ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_model(model, vocab): \n",
    "    \"\"\" Merges model and vocabulary into a DataFrame for scikit-learn. \"\"\"\n",
    "    model_df = pd.DataFrame.from_dict(dict(zip(vocab, model.wv)), orient='index')\n",
    "    print(\"Model shape (vocabulary x dimensions):\", model_df.shape)\n",
    "    return model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56198c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(model_df, num_clusters): \n",
    "    \"\"\" Performs the clustering of words based on the similarity of their vectors. \"\"\"\n",
    "    clusterer = Birch(n_clusters = num_clusters)\n",
    "    clusterer.fit(model_df)\n",
    "    clusters = clusterer.predict(model_df)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ee4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_results(clusters, vocab): \n",
    "    \"\"\" Maps the cluster numerical members onto the actual vocabulary.\n",
    "    Groups all words of a cluster into one list / line in a dataframe. \"\"\"\n",
    "    mapped = pd.DataFrame.from_dict(dict(zip(vocab, clusters)), \n",
    "        orient=\"index\", columns=[\"cluster\"]).reset_index().rename(columns = {'index':'word'})\n",
    "    grouped = mapped.groupby(by=\"cluster\")[\"word\"].apply(list).reset_index(name = \"words\").set_index(\"cluster\")\n",
    "    grouped[\"size\"] = grouped[\"words\"].apply(len)\n",
    "    grouped[\"words\"] = grouped[\"words\"].apply(sorted).apply(\", \".join)\n",
    "    grouped.sort_values(by=\"size\", ascending=True, inplace=True)\n",
    "    word_clusters = grouped[[\"size\", \"words\"]]\n",
    "    #print(word_clusters.head())\n",
    "    return word_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95194f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(word_clusters, resultsfile): \n",
    "    \"\"\" Saves the results to disk as a TSV file. \"\"\"\n",
    "    with open(resultsfile, \"w\", encoding=\"utf8\") as outfile: \n",
    "        word_clusters.to_csv(outfile, sep=\"\\t\")\n",
    "    print(\"Saved results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a6912",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "104a3a6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../../../../Dropbox/06-Analysen/2017/w2v/models/frwiki17_mdt=skgr-opt=negsam-itr=20-dim=200-win=8-min=200.gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16888/2723845790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#save_results(word_clusters, resultsfile)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultsfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_16888/2723845790.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(modelfiles, modelname, num_clusters, resultsfile)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultsfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodelfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#model_df = transform_model(model, vocab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#clusters = perform_clustering(model_df, num_clusters)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_16888/113698790.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(modelfile)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\" Loads an existing word2vec model in Keyed vector format. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1928\u001b[0m         \"\"\"\n\u001b[1;32m   1929\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1930\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1931\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \"\"\"\n\u001b[0;32m-> 1459\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../../../../Dropbox/06-Analysen/2017/w2v/models/frwiki17_mdt=skgr-opt=negsam-itr=20-dim=200-win=8-min=200.gensim'"
     ]
    }
   ],
   "source": [
    "def main(modelfiles, modelname, num_clusters, resultsfile): \n",
    "    modelfile = modelfiles[modelname]\n",
    "    model, vocab = load_model(modelfile)\n",
    "    #model_df = transform_model(model, vocab)\n",
    "    #clusters = perform_clustering(model_df, num_clusters)\n",
    "    #word_clusters = transform_results(clusters, vocab)\n",
    "    #save_results(word_clusters, resultsfile)\n",
    "\n",
    "main(modelfiles, modelname, num_clusters, resultsfile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b5d270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python397jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
